# Image-Captioning-AI

This project uses the **BLIP** (Bootstrapping Language-Image Pre-training) model to generate captions for images. Upload an image, and the AI will describe it!   
 
---

## âš™ï¸ **Technologies Used:**

* Python
* BLIP Model by Salesforce   
* Transformers (Hugging Face)
* Gradio, Pillow, Requests

---

## ğŸ”§ **Installation:**

1. **Clone the Repo**:

   ```bash
   git clone https://github.com/YOUR_GITHUB_USERNAME/image-captioning-ai.git
   ```
2. **Install Dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ“¸ **How to Use:**

1. Place your image in the project folder or update the `img_path` in `image_cap.py`.
2. Run the script:

   ```bash
   python image_cap.py
   ```

---

## ğŸ“œ **Example Output**:

```
"A dog playing in the grass."
```

---

### Enjoy using AI to describe images! âœ¨

---

